{
    "name": "Human Action Recognition",
    "usedfor": "Recognize human activity boardwalk or sporting scenary with tracking",
    "consideration": "- Depending on the interval, a person might not be observed\n- A person must be within close proximity\n- Weather visibility might affect the results ",
    "assumption": "For the stream, depending on the interval, the sampling rate is going to be a frame per second or slower.",
    "results_description": "Video with pose estimation",
    "structure":{
        "feeds": {
            "sources": [
                "video"
            ],
            "params":[
                {
                    "name": "filename",
                    "type": "string",
                    "disc": "filepath for video in case of streaming from video file",
                    "source": "infered",
                    "default": null
                },
                {
                    "name": "sample_every",
                    "type": "int",
                    "disc": "Sample every (seconds for stream and frame for video)",
                    "source": "user",
                    "default": 1
                },
                {
                    "name": "length",
                    "type": "float",
                    "disc": "Length of streaming (seconds, -1 for entire video)",
                    "source": "user",
                    "default": -1
                },
                {
                    "name": "frequency",
                    "type": "int",
                    "disc": "Output frequency (every n frame)",
                    "source": "user",
                    "default": 5
                },
                {
                    "name": "size",
                    "type": "string",
                    "disc": "Resize your video to (width,height) for faster prediction. (-1) for no resizing",
                    "source": "user",
                    "default": "640,360"
                },
                {
                    "name": "ntasks",
                    "type": "int",
                    "disc": "Number of tcp process at a time",
                    "source": "user",
                    "default": 4
                }
            ]
        },
        "nodes": [
            {
                "name": "stream_source",
                "type": "VideoFileSource",
                "filename": "$filename",
                "length": "$length",
                "sample_every": "$sample_every"
            },
            {
                "name": "resizer",
                "type": "Resizer",
                "size": "$size"
            },
            {
                "name": "sequence_runner_resizer",
                "type": "SequenceRunner",
                "frequency": "1",
                "nodes": [
                    "resizer"
                ]
            },
            {
                "name": "tfpose_model",
                "type": "TFModel",
                "model_name": "tfpose",
                "version": 1,
                "protocol": "gRPC",
                "input_name": "input_1"
            },
            {
                "name": "tfpose_model_thread",
                "type": "ConcurrentTFgRPCTasksThreadWrapper",
                "node": "tfpose_model",
                "ntasks": "$ntasks",
                "max_send_message_length": 6230000
            },
            {
                "name": "falcoeye_hpe",
                "type": "FalcoeyeTFOpenPoseNode"
            },
            {
                "name": "hpe_drawer",
                "type": "HPEDrawer"
            },
            {
                "name": "reid_model",
                "type": "TorchModel",
                "model_name": "reid",
                "version": 1,
                "protocol": "gRPC"
            },
            {
                "name": "har_model",
                "type": "TorchModel",
                "model_name": "har",
                "version": 1,
                "protocol": "gRPC"
            },
            {
                "name": "sequence_maintainer",
                "type": "SortedSequence"
            },
            {
                "name": "deep_sort_tracker",
                "type": "DeepSortTracker",
                "feature_extractor_node":"reid_model"
            },
            {
                "name": "mpc",
                "type": "MultiPersonClassifier",
                "model_node":"har_model",
                "classes":["stand", "walk", "run", "jump", "sit", "squat", "kick", "punch", "wave"]
            },
            {
                "name": "video_writer",
                "type": "ActiveVideoWriter",
                "prefix": "$prefix"
            },
            {
                "name": "finalizer",
                "type": "Finalizer",
                "prefix": "$prefix"
            },
            {
                "name": "sequence_runner",
                "type": "SequenceRunner",
                "frequency": "$frequency",
                "nodes": [
                    "falcoeye_hpe",
                    "sequence_maintainer",
                    "deep_sort_tracker",
                    "mpc",
                    "hpe_drawer",
                    "video_writer",
                    "finalizer"
                ]
            }
        ],
        "edges": [
            ["stream_source","sequence_runner_resizer"],
            ["resizer","tfpose_model_thread"],
            ["falcoeye_hpe","sequence_maintainer"],
            ["sequence_maintainer","deep_sort_tracker"],
            ["deep_sort_tracker","mpc"],
            ["mpc","hpe_drawer"],
            ["hpe_drawer","video_writer"],
            ["tfpose_model_thread","sequence_runner"]
        ],
        "starters":["stream_source"],
        "run_order": [
            "sequence_runner",
            "tfpose_model_thread",
            "sequence_runner_resizer",
            "stream_source"
        ]
    }
}
